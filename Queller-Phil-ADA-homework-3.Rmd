---
title: "Queller-Phil-ADA-homework-3"
author: "Phil Queller"
date: "4/26/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


library(tidyverse)
library(broom)
library(infer)

```

#Challenge 1

```{r}

#read in data

k <-read.csv("~/Desktop/KamilarDATA.csv")
head(k)

```

For this exercise, the end aim is to fit a simple linear regression model to predict longevity (MaxLongevity_m) measured in months from species’ brain size (Brain_Size_Species_Mean) measured in grams. Do the following for both longevity~brain size and log(longevity)~log(brain size). Fit the regression model and, using {ggplot2}, produce a scatterplot with the fitted line superimposed upon the data. Append the the fitted model equation to your plot.

```{r}

r <- lm(MaxLongevity_m ~ Brain_Size_Species_Mean, data = k, level = 0.90)

tidy(r) 
  
  

  


confint(r, level = 0.90)

m.summary <- tidy(r) 

raw <- ggplot(data = k, aes(x = Brain_Size_Species_Mean, y = MaxLongevity_m)) +
            geom_point() + 
            geom_smooth(method = "lm", formula = y ~ x, level = 0.90) +
            geom_text(x = 200, y = 800, label = "y = 248.9523 + 1.218(Xi) + Ei")
print(raw)


fit <- lm(log(MaxLongevity_m) ~ log(Brain_Size_Species_Mean), data = k, level = 0.90)
tidy(fit)
log <- ggplot(data = k, aes(x = log(Brain_Size_Species_Mean), y = log(MaxLongevity_m))) +
            geom_point() + 
            geom_smooth(method = "lm", formula = y ~ x, level = 0.90) +
              geom_text(x = 4.2, y = 5, label = "y = 4.87895 + 0.23415(Xi) + Ei, where E ~ (0, (0.2485) ^2")
print(log)


alpha <- 0.1
ci <- predict(r,
  newdata = data.frame(Brain_Size_Species_Mean = seq(min(k$Brain_Size_Species_Mean, na.rm = TRUE), max(k$Brain_Size_Species_Mean, na.rm = TRUE), by = 1)),
  interval = "confidence", level = 1 - alpha
)
ci <- data.frame(ci)
ci <- cbind(seq(min(k$Brain_Size_Species_Mean, na.rm = TRUE), max(k$Brain_Size_Species_Mean, na.rm = TRUE), by = 1), ci)


pi <- predict(r,
  newdata = data.frame(Brain_Size_Species_Mean = seq(min(k$Brain_Size_Species_Mean, na.rm = TRUE), max(k$Brain_Size_Species_Mean, na.rm = TRUE), by = 1)),
  interval = "prediction", level = 1 - alpha
)
pi <- data.frame(pi)
head(pi)


i <- cbind(ci, pi)
head(i)

names(i) <- c("weight", "c.fit", "c.lwr", "c.upr", "p.fit", "p.lwr", "p.upr")
view(i)

long <- pivot_longer(i, c.fit:p.upr, names_to = "model")

g <- ggplot(data = k, aes(x = Brain_Size_Species_Mean, y = MaxLongevity_m)) +
  geom_point(alpha = 0.5) +
  geom_line(data = long, aes(x = weight, y = value, group = model, color = model))

g

beta0 <- m.summary %>%
  filter(term == "(Intercept)") %>%
  pull(estimate)
beta1 <- m.summary %>%
  filter(term == "Brain_Size_Species_Mean") %>%
  pull(estimate)
(h.hat <- beta1 * 750 + beta0)


```

Identify and interpret the point estimate of the slope (β1), as well as the outcome of the test associated with the hypotheses H0:β1=0,HA:β1≠0. Also, find a 90% CI for the slope (β1) parameter.


longevity ~ brainsize:

B1 = 1.218, p < 2e-16. Longevity is positively correlated with brainsize. 

```{r}



```

log(longevity) ~ log(brainsize):

B1 = 0.23415, p < 2e-16. Longevity is positively correlated with brainsize. 



Using your model, add lines for the 90% confidence and prediction interval bands on the plot, and add a legend to differentiate between the lines.


```{r}





```



Produce a point estimate and associated 90% prediction interval for the longevity of a species whose brain weight is 750 gm. Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?







#Challenge 2

Using the “KamilarAndCooperData.csv” dataset, run a linear regression looking at log(HomeRange_km2) in relation to log(Body_mass_female_mean) and report your β coeffiecients (slope and intercept).

```{r}

fit <- lm(log(HomeRange_km2) ~ log(Body_mass_female_mean), data = k)
summary(fit)

```
B0 = -9.44123
B1 = 1.03643


Then, use bootstrapping to sample from the dataset 1000 times with replacement, each time fitting the same model and calculating the appropriate coefficients. [The size of each sample should be equivalent to the total number of observations in the dataset.] This generates a bootstrap sampling distribution for each β coefficient. Plot a histogram of these sampling distributions for β0 and β1.

```{r}




boot <- data.frame()

  for (i in 1:1000) {
  s <- sample_n(k, size = nrow(k), replace = TRUE)
  fit <- lm(s, formula = log(HomeRange_km2) ~ log(Body_mass_female_mean))
  tidy(fit) %>%
  print(estimate) -> results
  boot <- c(boot, results)
}


  
boot

```


# Challenge 3

Write your own function, called boot_lm(), that takes as its arguments a dataframe (d=), a linear model (model=, written as a character string, e.g., “logHR ~ logBM”), a user-defined confidence interval level (conf.level=) with default “0.95”, and a number of bootstrap replicates (reps=, with default “1000”).

Your function should return a dataframe that includes: the β
coefficient names; the value of the β coefficients, their standard errors, and their upper and lower CI limits for the linear model based on your original dataset; and the mean β coefficient estimates, SEs, and CI limits for those coefficients based on your bootstrap.

Use your function to run the following models on the “KamilarAndCooperData.csv” dataset:

    log(HomeRange_km2) ~ log(Body_mass_female_mean)
    log(DayLength_km) ~ log(Body_mass_female_mean)
    log(HomeRange_km2) ~ log(Body_mass_female_mean) + MeanGroupSize

```{r}

  boot_lm <- function(d, model, conf.level = 0.95, reps = 1000) {
  
  

   fit <- lm(d, formula = model)
  tidy(fit, conf.int = TRUE, conf.level = conf.level)

  

boot <- tibble()

for (i in 1:reps) {
  s <- sample_n(d, size = nrow(k), replace = TRUE)
  fit <- lm(s, formula = model)
  tidy(fit, conf.int = TRUE, conf.level = conf.level) %>%
  pull(estimate) -> results
  boot <- c(boot, results)
}

return(boot)
  
}

m <- boot_lm(k, "log(HomeRange_km2) ~ log(Body_mass_female_mean)")
view(m)
```